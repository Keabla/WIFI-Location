#merge
Train_Data$Which_DT <- "T"
Val_Data$Which_DT <- "V"
Total_DT <- rbind(Train_Data,Val_Data)
#Preparation for data
Train_Data$FLOOR <- ordered(Train_Data$FLOOR)
Train_Data$BUILDINGID <- as.factor(Train_Data$BUILDINGID)
#plot different datasets
Plot_Total_3D <- plot_ly(Total_DT, x =~LONGITUDE, y =~LATITUDE, z=~FLOOR, color = ~Which_DT,
colors = c('#BF382A', '#0C4B8E')) %>%
add_markers()
Plot_Total_3D
#Plot 3D with the the number of observation per WAP for Training and Validation
Plot_Train_3D <- plot_ly(Train_Data, x =~LONGITUDE, y =~LATITUDE, z=~FLOOR,
marker = list(color = ~Diff_Obs, colorscale = c("Portland"), showscale = TRUE)) %>%
add_markers()
Plot_Train_3D
Plot_Val_3D <- plot_ly(Val_Data, x =~LONGITUDE, y =~LATITUDE, z=~FLOOR,
marker = list(color = ~Diff_Obs, colorscale = c('#FFE1A1', '#683531'), showscale = TRUE)) %>%
add_markers()
Plot_Val_3D
#Number of observations per floor and per building
Exploration_distribution  <- ggplot(data = Train_Data) +
aes(x = BUILDINGID, y = FLOOR) +
geom_jitter(size = 0.1) +
theme_minimal()+
ggtitle("Count Floor Building")+
geom_bin2d(bins = 30)
Exploration_distribution
### Packages
pacman::p_load(caret,lubridate,dplyr,tidyr,skimr,ggplot2,scales,fracdiff,imputeTS,
edeaR,doParallel,urca,forecast,anytime,reshape,randomForest,class,e1071,
rstudioapi,plotly)
### Path
current_path = getActiveDocumentContext()$path
setwd(dirname(current_path))
setwd("..")
source("Scripts/Step_1_Data_Exploration.R")
#Grep function to get the WAP columns
WAP_Train <- grep("WAP",colnames(Train_Data),value = TRUE)
WAP_Val <- grep("WAP",colnames(Val_Data),value = TRUE)
#drop Columns that have zero variance for validation set and Training Set
ZV <- nearZeroVar(Train_Data, freqCut = 100/0)
Train_Data[,ZV] <- NULL
ZV <- nearZeroVar(Val_Data, freqCut = 100/0)
Val_Data[,ZV] <- NULL
#keep columns in the training set that are meaningful in the validation set
Same_Col <- intersect(colnames(Train_Data),colnames(Val_Data))
Val_Data <- Val_Data[,Same_Col]
Train_Data <- Train_Data[,Same_Col]
#check for missing values
sum(is.na(Train_Data))
#Drop variables that are not useful for our analysis as they are not useful for our analysis
Train_Data$TIMESTAMP <- NULL
#Drop PhoneID as there are
length(unique(Train_Data$PHONEID)) == length(unique(Val_Data$PHONEID))
Train_Data$PHONEID <- NULL
#change variable types
Train_Data$FLOOR <- ordered(Train_Data$FLOOR)
Train_Data$BUILDINGID <- as.factor(Train_Data$BUILDINGID)
Val_Data$FLOOR <- ordered(Val_Data$FLOOR)
Val_Data$BUILDINGID <- as.factor(Val_Data$BUILDINGID)
ID <- colnames(select(Train_Data, -contains("WAP")))
str(Train_Data[,ID])
#Drop any row that has less than 4 unique observations, as one of them is -120 bmp (Absence of Signal) and
#the rest we need at least three observations to create a model because of True range multilateration
Train_Data <- Train_Data %>% filter(Uni_Obs >3)
#Drop any row that has less than 4 unique observations, as one of them is -120 bmp (Absence of Signal) and
#the rest we need at least three observations to create a model because of True range multilateration
Train_Data <- Train_Data %>% filter(Diff_Obs >3)
Train_Data <- Train_Data %>% mutate(id_row = row_number())
Val_Data <- Val_Data %>% filter(Diff_Obs > 3)
#Create new variables in both datasets for First, Second and Third MAx
WAP_Train <- grep("WAP",colnames(Train_Data),value = TRUE)
#Make sure that the two sets have the same columns
Same_Col <- intersect(colnames(Train_Data),colnames(Val_Data))
Train_Data <- Train_Data[,Same_Col]
Val_Data <- Val_Data[,Same_Col]
#Merge the two dataset
Train_Data$Which_DT <- "T"
Val_Data$Which_DT <- "V"
Total_DT <- rbind(Train_Data,Val_Data)
Total_DT$N_Row <- seq.int(nrow(Total_DT))
#Sample of Train Separated
Count_Table <- Total_DT %>% group_by(Uni_ID_POS) %>% summarise(count=n())
Count_Table
N_Sampling <- min(Count_Table$count)
N_Sampling
Sample_Total <- Total_DT %>% group_by(Uni_ID_POS) %>% sample_n(N_Sampling)
Count_Table <- Sample_Total %>% group_by(Uni_ID_POS) %>% summarise(count=n())
Count_Table
#filter Total_DT data
Which_Row <- Total_DT$N_Row
Which_No_Row <- Sample_Total$N_Row
Which_Row <- Which_Row[-Which_No_Row]
No_Sample_DT <- Total_DT[Which_Row,]
nrow(Total_DT)
nrow(Sample_Total)
nrow(No_Sample_DT)
train <- Sample_Total
test <- No_Sample_DT
ID <- colnames(select(train, -contains("WAP")))
str(train[,ID])
str(test[,ID])
RFFIT_Uni_TD <- readRDS("Models/RFFIT_Uni_TD.rds")
KNNFIT_Uni_TD <- readRDS("Models/KNNFIT_Uni_TD.rds")
##RF
#predicting values
pred_RFFIT_Val_Uni<-predict(RFFIT_Uni_TD, test)
pred_RFFIT_Train_Uni <- predict(KNNFIT_Uni_TD, train)
#post for unique ID variable
pred.metric_RFFIT_Val_Uni <- postResample(pred_RFFIT_Val_Uni, test$Uni_ID_POS)
pred.metric_RFFIT_Train_Uni <- postResample(pred_RFFIT_Train_Uni, train$Uni_ID_POS)
#Separate Floor and building for Validation Set PostResample
pred_RFFIT_Val_Uni <- as.data.frame(pred_RFFIT_Val_Uni)
pred_RFFIT_Val_B_F <- pred_RFFIT_Val_Uni %>% separate(1,into = c("BUILDINGID","FLOOR"), sep = "_")
pred_RFFIT_Val_B_F$FLOOR <- as.ordered(pred_RFFIT_Val_B_F$FLOOR)
pred_RFFIT_Val_B_F$BUILDINGID <- as.factor(pred_RFFIT_Val_B_F$BUILDINGID)
#post for Validation separate
pred.metric_RFFIT_Val_F <- postResample(pred_RFFIT_Val_B_F$FLOOR,test$FLOOR)
pred.metric_RFFIT_Val_B <- postResample(pred_RFFIT_Val_B_F$BUILDINGID,test$BUILDINGID)
pred.metric_RFFIT_Val_F
pred.metric_RFFIT_Val_B
#Separate Floor and building for Training Set PostResample
pred_RFFIT_Train_Uni <- as.data.frame(pred_RFFIT_Train_Uni)
pred_RFFIT_Train_B_F <- pred_RFFIT_Train_Uni %>% separate(1,into = c("BUILDINGID","FLOOR"), sep = "_")
pred_RFFIT_Train_B_F$FLOOR <- as.ordered(pred_RFFIT_Train_B_F$FLOOR)
pred_RFFIT_Train_B_F$BUILDINGID <- as.factor(pred_RFFIT_Train_B_F$BUILDINGID)
#post for Training separate
pred.metric_RFFIT_Train_F <- postResample(pred_RFFIT_Train_B_F$FLOOR,train$FLOOR)
pred.metric_RFFIT_Train_B <- postResample(pred_RFFIT_Train_B_F$BUILDINGID,train$BUILDINGID)
pred.metric_RFFIT_Val_F
pred.metric_RFFIT_Val_B
RFFIT_Lon_TD <- readRDS("Models/RFFIT_Lon_TD.rds")
pred_RFFIT_Val_Lon <-  predict(RFFIT_Lon_TD,test)
pred_RRFIT_Test_Lon <- predict(RFFIT_Lon_TD,train)
#Post resample RFFIT_Lon
pred.metric_RFFIT_Val_Lon <- postResample(pred_RFFIT_Val_Lon,test$LONGITUDE)
pred.metric_RFFIT_Train_Lon <- postResample(pred_RRFIT_Test_Lon,train$LONGITUDE)
pred.metric_RFFIT_Val_Lon
RFFIT_Lat_TD <- readRDS("Models/RFFIT_Lat_TD.rds")
pred_RFFIT_Val_Lat <-  predict(RFFIT_Lat,test)
pred_RRFIT_Train_Lat <- predict(RFFIT_Lat,train)
#Post resample RFFIT_Lat
pred.metric_RFFIT_Val_Lat <- postResample(pred_RFFIT_Val_Lat,test$LATITUDE)
pred.metric_RFFIT_Train_Lat <- postResample(pred_RRFIT_Train_Lat,train$LATITUDE)
pred_RFFIT_Val_Lat <-  predict(RFFIT_Lat_TD,test)
pred_RRFIT_Train_Lat <- predict(RFFIT_Lat_TD,train)
#Post resample RFFIT_Lat
pred.metric_RFFIT_Val_Lat <- postResample(pred_RFFIT_Val_Lat,test$LATITUDE)
pred.metric_RFFIT_Train_Lat <- postResample(pred_RRFIT_Train_Lat,train$LATITUDE)
pred.metric_RFFIT_Val_Lat
#creating a new column
test$BUILDINGIDp<-pred_RFFIT_Val_B_F$BUILDINGID
test$FLOORp <- pred_RFFIT_Val_B_F$FLOOR
test$Uni_ID_POSp <- pred_RFFIT_Val_Uni$pred_RFFIT_Val_Uni
#rows of elements where there is a differnece between prediciton and actual value
#which function returns row numbers when comparing two colums (== equal, != unequal)
pred.metric_RFFIT_Val_F <- postResample(pred_RFFIT_Val_B_F$FLOOR,test$FLOOR)
#Create vectors to select errors
ErrorRF_B <- which(test$BUILDINGIDp != test$BUILDINGID)
ErrorRF_F <- which(test$FLOORp != test$FLOOR)
ErrorRF_Uni <- which(test$Uni_ID_POS != test$Uni_ID_POSp)
test$ER_RF_B <- 0
test$ER_RF_F <- 0
test$ER_RF_Uni <- 0
#transform in 1 the to get the errors
test$ER_RF_B[ErrorRF_B] <- 1
test$ER_RF_F[ErrorRF_F] <- 1
test$ER_RF_Uni[ErrorRF_Uni] <- 1
#factorize results
test$ER_RF_B <- as.factor(test$ER_RF_B)
test$ER_RF_F <- as.factor(test$ER_RF_F)
test$ER_RF_Uni <- as.factor(test$ER_RF_Uni)
Plot_P_VS_R_UOBs <- ggplot(data = test, aes(x = Uni_ID_POS, y = Uni_ID_POSp)) +
geom_jitter(aes(colour=ER_RF_Uni)) +
theme_minimal() +
ggtitle("Predicted Values VS Actual Values") +
theme(plot.title = element_text(hjust = 0.5))
Plot_P_VS_R_UOBs
#Number of observations per floor and per building
Sample_distribution <- ggplot(data = Sample_Total) +
aes(x = BUILDINGID, y = FLOOR) +
geom_jitter(size = 0.1) +
theme_minimal() +
ggtitle("Observations per Floor per Building Sample") +
theme(plot.title = element_text(hjust = 0.5)) +
geom_bin2d(bins = 30)
Sample_distribution
Plot_Sample_3D <- plot_ly(Sample_Total, x =~LONGITUDE, y =~LATITUDE, z=~FLOOR,
marker = list(color = ~Uni_Obs, colorscale = c('#FFE1A1', '#683531'), showscale = TRUE)) %>%
add_markers()
Plot_Sample_3D
Plot_Sample_3D <- plot_ly(Sample_Total, x =~LONGITUDE, y =~LATITUDE, z=~FLOOR,
marker = list(color = ~Diff_Obs, colorscale = c('#FFE1A1', '#683531'), showscale = TRUE)) %>%
add_markers()
Plot_Sample_3D
setwd(dirname(current_path))
setwd("..")
getwd()
#Library#####
pacman::p_load(
"Matrix",
"arules",
"caret",
"lattice",
"reshape2",
"RColorBrewer",
"arulesViz",
"prabclus",
"DEoptimR",
"trimcluster",
"dplyr",
"tidyr",
"ggplot2",
"skimr",
"imputeTS",
"lubridate",
"padr",
"forecast",
"imputeTS",
"gridGraphics",
"TTR",
"tseries",
"randomForest",
"matrixStats")
#Read Data####
location <- read.csv("C:/Users/Martin Albaek/Documents/coding academy/Ubiqum/Course/Module 3/Wi-Fi location/Wi-Fi Location/Datasets/trainingData.csv")
validation <- read.csv("C:/Users/Martin Albaek/Documents/coding academy/Ubiqum/Course/Module 3/Wi-Fi location/Wi-Fi Location/Datasets/validationData.csv")
#Library#####
pacman::p_load(
"Matrix",
"arules",
"caret",
"lattice",
"reshape2",
"RColorBrewer",
"arulesViz",
"prabclus",
"DEoptimR",
"trimcluster",
"dplyr",
"tidyr",
"ggplot2",
"skimr",
"imputeTS",
"lubridate",
"padr",
"forecast",
"imputeTS",
"gridGraphics",
"TTR",
"tseries",
"randomForest",
"matrixStats")
#Read Data####
location <- read.csv("C:/Users/Martin Albaek/Documents/coding academy/Ubiqum/Course/Module 3/Wi-Fi location/Wi-Fi Location/Datasets/trainingData.csv")
validation <- read.csv("C:/Users/Martin Albaek/Documents/coding academy/Ubiqum/Course/Module 3/Wi-Fi location/Wi-Fi Location/Datasets/validationData.csv")
#Transformation####
loc <- location[c(521:529, 1:520)]
loc <- unique(loc)
val <- validation[c(521:529, 1:520)]
WAP_Train
#Indexing
loc$ID <- seq.int(nrow(loc))
val$ID <- seq.int(nrow(val))
loc <- loc[,c(ncol(loc), 1:(ncol(loc)-1))]
val <- val[,c(ncol(val), 1:(ncol(val)-1))]
#Formating
loc$TIMESTAMP <- as.POSIXct(loc$TIMESTAMP, origin = "1970-01-01")
val$TIMESTAMP <- as.POSIXct(val$TIMESTAMP, origin = "1970-01-01")
factors <- c("SPACEID", "RELATIVEPOSITION", "BUILDINGID", "USERID", "PHONEID", "FLOOR")
for (i in factors) {
loc[,i] <- as.factor(loc[,i])
}
for (j in factors) {
val[,j] <- as.factor(val[,j])
}
rm(factors, i, j)
#Rename levels to be predicted (building and floor)
loc$FLOOR<-factor(loc$FLOOR,
levels = c(0, 1,2,3,4),
labels = c("ground", "first", "second", "third", "fourth")
)
loc$BUILDINGID<-factor(loc$BUILDINGID,
levels = c(0,1,2),
labels = c("TI", "TD", "TC")
)
val$FLOOR<-factor(val$FLOOR,
levels = c(0, 1,2,3,4),
labels = c("ground", "first", "second", "third", "fourth")
)
val$BUILDINGID<-factor(val$BUILDINGID,
levels = c(0,1,2),
labels = c("TI", "TD", "TC")
)
#replace 100 with -105 and remove outliers -> set values too good to -40
loc_WAP <- select(loc, starts_with("WAP"))
loc_factor <- select(loc, -starts_with("WAP"))
loc_WAP[loc_WAP==100]<--105
val_WAP <- select(val, starts_with("WAP"))
#Library#####
pacman::p_load(
"Matrix",
"arules",
"caret",
"lattice",
"reshape2",
"RColorBrewer",
"arulesViz",
"prabclus",
"DEoptimR",
"trimcluster",
"dplyr",
"tidyr",
"ggplot2",
"skimr",
"imputeTS",
"lubridate",
"padr",
"forecast",
"imputeTS",
"gridGraphics",
"TTR",
"tseries",
"randomForest",
"matrixStats")
#replace 100 with -105 and remove outliers -> set values too good to -40
loc_WAP <- select(loc, starts_with("WAP"))
loc_factor <- select(loc, -starts_with("WAP"))
# Import training dataset
trainingData <- read_csv("C:/Users/Martin Albaek/Documents/coding academy/Ubiqum/Course/Module 3/Wi-Fi location/Wi-Fi Location/Datasets/trainingData.csv")
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ LIBRARIES ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
library(readr)
library(dplyr)
library(ggplot2)
library(scatterplot3d)
library(corrplot)
library(caret)
library(som)
library(data.table)
library(randomForest)
library(doParallel)
clusterM <- makeCluster(detectCores()-1)
registerDoParallel(clusterM)
# Import training dataset
trainingData <- read_csv("C:/Users/Martin Albaek/Documents/coding academy/Ubiqum/Course/Module 3/Wi-Fi location/Wi-Fi Location/Datasets/trainingData.csv")
oriTrain <- trainingData
# Import validation dataset
validation <- read_csv("C:/Users/Martin Albaek/Documents/coding academy/Ubiqum/Course/Module 3/Wi-Fi location/Wi-Fi Location/Datasets/validationData.csv")
oriTest <- validation
vars_not_waps <- colnames(oriTrain[,521:529])
meltTrain <- melt(oriTrain, id.vars = vars_not_waps)
rm(vars_not_waps,long_train)
names(meltTrain)[10]<- paste("WAPid")
names(meltTrain)[11]<- paste("WAPrecord")
TIplot <- trainingData[,521:529]
z <- as.numeric(TIplot$FLOOR)
x <- TIplot$LONGITUDE
y <- TIplot$LATITUDE
scatterplot3d(x, y, z, pch = 20, angle = 75, color = TIPLOT$RELATIVEPOSITION, main = "Building Log In points")
TIplot <- trainingData[,521:529]
z <- as.numeric(TIplot$FLOOR)
x <- TIplot$LONGITUDE
y <- TIplot$LATITUDE
scatterplot3d(x, y, z, pch = 20, angle = 75, color = TIplot$RELATIVEPOSITION, main = "Building Log In points")
trainingData$z <- NULL
rm(x,y,z, TIplot)
# Training dataset
trainingData <- select_if(trainingData[,1:520], (function(x) mean(x) != 100))
trainingData[,466:474] <- oriTrain[,521:529]
# Test dataset
validation <- select_if(validation[,1:520], (function(x) mean(x) != 100))
validation[,368:376] <- oriTest[,521:529]
# Remove rows (WAP) where all the values = 100 (WAP was not detected)
# Training dataset
trainingData$mean1 <- rowMeans(trainingData[,1:465])
trainingData <-  filter(trainingData, mean1 != 100 )
trainingData <- unique(trainingData)
validation<- unique(validation)
# # Test dataset
validation$mean1 <- rowMeans(validation[,1:367])
validation <-  filter(validation, mean1 != 100 )
# Converting data types
# Training dataset
trainingData$FLOOR <- as.factor(trainingData$FLOOR)
trainingData$BUILDINGID <- as.factor(trainingData$BUILDINGID)
trainingData$RELATIVEPOSITION <- as.factor(trainingData$RELATIVEPOSITION)
trainingData$USERID <- as.factor(trainingData$USERID)
trainingData$PHONEID <- as.factor(trainingData$PHONEID)
# Test dataset
validation$FLOOR <- as.factor(validation$FLOOR)
validation$BUILDINGID <- as.factor(validation$BUILDINGID)
validation$PHONEID <- as.factor(validation$PHONEID)
# Change WAP values so that no signal is 0 and highest signal is 104
# Training Data
trainingData[trainingData == 100] <- -105
trainingData[,1:465] <- trainingData[,1:465] + 105
# Test data
validation[validation == 100] <- -105
validation[,1:367] <- validation[,1:367] + 105
# Check distribution of signal strength
# training data
trainWap <- trainingData[,1:465]
trainWap <- stack(trainWap)
trainWap <- trainWap[-grep(0, trainWap$values),]
hist(trainWap$values, xlab = "WAP strength", main = "Distribution of WAPs signal strength (Training set)", col = "purple")
trainWap
# test data
testWap<- validation[,1:367]
testWap <- stack(testWap)
testWap <- testWap[-grep(0, testWap$values),]
hist(testWap$values, xlab = "WAP strength", main = "Distribution of WAPs signal stength (Test set)", col = "blue")
ggplot() +
geom_histogram(data = trainWap, aes(values), fill = "red", alpha = 1, binwidth = 5) +
geom_histogram(data = testWap, aes(values), fill = "blue", alpha = 1, binwidth = 5) +
ggtitle("Distribution of WAPs signal strength (Train Set and Test Set)") +
xlab("WAP strength")
# Check distribution of how many WAPs have signal
# TRAINING SET
trainingData$count <- rowSums(trainingData[, 1:465] != 0)
ggplot(trainingData, aes(count, fill = as.factor(trainingData$BUILDINGID))) +
geom_histogram(binwidth = 2)+
ggtitle("Number of WAPs detected per building (Training set)") +
scale_fill_manual(name="Buildings", values = c("0" = "royalblue2",
"1" = "firebrick2",
"2" = "springgreen1"),
labels=c("TI","TD", "TC"))
# TEST SET
validation$count <- rowSums(validation[, 1:367] != 0)
ggplot(validation, aes(count, fill = as.factor(validation$BUILDINGID))) +
geom_histogram(binwidth = 2)+
ggtitle("Number of WAPs detected per building (Test set)") +
scale_fill_manual(name="Buildings", values = c("0" = "royalblue2",
"1" = "firebrick2",
"2" = "springgreen1"),
labels=c("TI","TD", "TC"))
# Locations at which users logged in
# Red colour is outside the room, black inside
p <- ggplot(trainingData, aes(trainingData$LONGITUDE, trainingData$LATITUDE))
p + geom_point(colour = as.factor(trainingData$RELATIVEPOSITION)) +
xlab("Longitude") +
ylab("Latitude") +
ggtitle ("Locations at which users logged in (Training dataset)")
# Training and Validation log in locations
ggplot() +
geom_point(data = trainingData, aes(x = LONGITUDE, y = LATITUDE, colour = "Training dataset")) +
geom_point(data = validation, aes(x = LONGITUDE, y = LATITUDE, colour = "Test dataset")) +
ggtitle("Log In Locations (Training and Test sets)")
trainSet <- trainingData[ ,1:469]
# Import validation dataset
testSet <- validation[,1:371]
gs <- which(apply(trainingData[, 1:465], 1, function(x) length(which(x > 60))) > 0)
strongSignal <- trainingData[gs, ]
gs <- ggplot(strongSignal, aes(strongSignal$LONGITUDE, strongSignal$LATITUDE))
gs + geom_point(colour = as.factor(strongSignal$RELATIVEPOSITION)) +
ggtitle("Log in locations where WAP signal was high") +
xlab("Longitude") +
ylab("Latitude")
trainingData$BuildingFloor <-  paste(trainingData$BUILDINGID, trainingData$FLOOR, sep = "-")
validation$BuildingFloor <- paste(validation$BUILDINGID, validation$FLOOR, sep = "-")
trainSet$BuildingFloor <-  paste(trainSet$BUILDINGID, trainSet$FLOOR, sep = "-")
testSet$BuildingFloor <- paste(testSet$BUILDINGID, testSet$FLOOR, sep = "-")
ggplot(data = trainingData) +
aes(x = LONGITUDE, y = LATITUDE, color = FLOOR) +
geom_point() +
theme_minimal()
ggplot(data = validation) +
aes(x = LONGITUDE, y = LATITUDE, color = FLOOR) +  # the same plot has been applied to test
geom_point() +          # and we can see that the samples are taken in a more arbitrary way
theme_minimal()
tooGood_signals <- meltTrain %>% filter(WAPrecord > -30)
# tooGood_signals boxplot by WAPS in each building
ggplot(data = tooGood_signals) +                      # we detect that almost all extreme signals come from
aes(x = WAPid, y = WAPrecord, fill = BUILDINGID) +  # the same building (TC)
geom_boxplot() +                                    # exept from one WAP in building TD
theme_minimal()+
theme(axis.text.x = element_text(angle = 90, hjust = 1))
# histogram tooGood_signals by bulding&floor to detect if these are concentrated in a specific floor
ggplot(data = tooGood_signals) +        # Indeed, these RSSI happen in floor 3&4 of building TC
aes(x = WAPrecord, fill = FLOOR) +
geom_histogram(bins = 30) +
theme_minimal() +
facet_wrap(vars(BUILDINGID))
# histogram tooGood_signals by bulding&floor to detect if these are concentrated in a specific floor
ggplot(data = tooGood_signals) +        # Indeed, these RSSI happen in floor 3&4 of building TC
aes(x = WAPrecord, fill = FLOOR) +
geom_histogram(bins = 30) +
theme_minimal() +
facet_wrap(vars(BUILDINGID))
# histogram to understand if tooGood_signals come from one specific phone model or user
ggplot(data = tooGood_signals) +
aes(x = PHONEID, fill = FLOOR) +
geom_bar() +
theme_minimal() +
facet_wrap(vars(BUILDINGID))     # phone 19 is responsible for the vast majority of them
ggplot(data = tooGood_signals) +
aes(x = USERID, fill = FLOOR) +
geom_bar() +
theme_minimal() +
facet_wrap(vars(BUILDINGID))     # phone 19 is used by user 6 (max responsible for >-30dbm RSSI)
Val_Data <- validationData
Train_Data <- trainingData
#Remove duplicates
Val_Data <- unique(Val_Data)
Train_Data <- unique(Train_Data)
pacman::p_load(caret,lubridate,dplyr,tidyr,skimr,ggplot2,scales,fracdiff,imputeTS,
edeaR,doParallel,urca,forecast,anytime,reshape,randomForest,class,e1071,
rstudioapi,plotly)
### Path
current_path = getActiveDocumentContext()$path
setwd(dirname(current_path))
